{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img,ImageDataGenerator, array_to_img\n",
    "from tensorflow.keras.applications import EfficientNetB1\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Flatten,Dense,Conv2D,Dropout,GlobalAveragePooling2D, MaxPooling2D\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciation modèle séquentiel\n",
    "lenet = Sequential()\n",
    "\n",
    "# Ajout des différentes couches\n",
    "lenet.add(Conv2D(filters = 30 , kernel_size = (5,5), input_shape =[256,256,1], activation = \"relu\"))\n",
    "lenet.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "lenet.add(Conv2D(filters = 16, kernel_size = (3,3), activation = \"relu\"))\n",
    "lenet.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "lenet.add(Flatten())\n",
    "lenet.add(Dropout(rate = 0.2))\n",
    "\n",
    "lenet.add(Dense(units = 128, activation = \"relu\"))\n",
    "lenet.add(Dense(units = 4, activation = \"softmax\"))\n",
    "\n",
    "# Compilation\n",
    "lenet.compile(loss = \"sparse_categorical_crossentropy\", optimizer = \"Adam\", metrics = [\"accuracy\"]) #LR default 10-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "axes don't match array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15800\\3424313428.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlenet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"C:/Users/Nina/Desktop/model_efNet7_1000mkd.h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Nina\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Nina\\anaconda3\\lib\\site-packages\\numpy\\core\\overrides.py\u001b[0m in \u001b[0;36mtranspose\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Nina\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mtranspose\u001b[1;34m(a, axes)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m     \"\"\"\n\u001b[1;32m--> 668\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'transpose'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    669\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Nina\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[1;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: axes don't match array"
     ]
    }
   ],
   "source": [
    "model = lenet\n",
    "model.load_weights(\"C:/Users/Nina/Desktop/model_efNet7_1000mkd.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VizGradCAM(model, image, interpolant=0.5, plot_results=True):\n",
    "\n",
    "    \"\"\"VizGradCAM - Displays GradCAM based on Keras / TensorFlow models\n",
    "    using the gradients from the last convolutional layer. This function\n",
    "    should work with all Keras Application listed here:\n",
    "    https://keras.io/api/applications/\n",
    "    Parameters:\n",
    "    model (keras.model): Compiled Model with Weights Loaded\n",
    "    image: Image to Perform Inference On\n",
    "    plot_results (boolean): True - Function Plots using PLT\n",
    "                            False - Returns Heatmap Array\n",
    "    Returns:\n",
    "    Heatmap Array?\n",
    "    \"\"\"\n",
    "    #sanity check\n",
    "    assert (interpolant > 0 and interpolant < 1), \"Heatmap Interpolation Must Be Between 0 - 1\"\n",
    "\n",
    "    #STEP 1: Preprocesss image and make prediction using our model\n",
    "    #input image\n",
    "    original_img = np.asarray(image, dtype = np.float32)\n",
    "    #expamd dimension and get batch size\n",
    "    img = np.expand_dims(original_img, axis=0)\n",
    "    #predict\n",
    "    prediction = model.predict(img)\n",
    "    #prediction index\n",
    "    prediction_idx = np.argmax(prediction)\n",
    "\n",
    "    #STEP 2: Create new model\n",
    "    #specify last convolutional layer\n",
    "    last_conv_layer = next(x for x in model.layers[::-1] if isinstance(x, tf.keras.layers.Conv2D))\n",
    "    target_layer = model.get_layer(last_conv_layer.name)\n",
    "\n",
    "    #compute gradient of top predicted class\n",
    "    with tf.GradientTape() as tape:\n",
    "        #create a model with original model inputs and the last conv_layer as the output\n",
    "        gradient_model = Model([model.inputs], [target_layer.output, model.output])\n",
    "        #pass the image through the base model and get the feature map  \n",
    "        conv2d_out, prediction = gradient_model(img)\n",
    "        #prediction loss\n",
    "        loss = prediction[:, prediction_idx]\n",
    "\n",
    "    #gradient() computes the gradient using operations recorded in context of this tape\n",
    "    gradients = tape.gradient(loss, conv2d_out)\n",
    "\n",
    "    #obtain the output from shape [1 x H x W x CHANNEL] -> [H x W x CHANNEL]\n",
    "    output = conv2d_out[0]\n",
    "\n",
    "    #obtain depthwise mean\n",
    "    weights = tf.reduce_mean(gradients[0], axis=(0, 1))\n",
    "\n",
    "\n",
    "    #create a 7x7 map for aggregation\n",
    "    activation_map = np.zeros(output.shape[0:2], dtype=np.float32)\n",
    "    #multiply weight for every layer\n",
    "    for idx, weight in enumerate(weights):\n",
    "        activation_map += weight * output[:, :, idx]\n",
    "    #resize to image size\n",
    "    activation_map = cv2.resize(activation_map.numpy(), \n",
    "                                (original_img.shape[1], \n",
    "                                 original_img.shape[0]))\n",
    "    #ensure no negative number\n",
    "    activation_map = np.maximum(activation_map, 0)\n",
    "    #convert class activation map to 0 - 255\n",
    "    activation_map = (activation_map - activation_map.min()) / (activation_map.max() - activation_map.min())\n",
    "    #rescale and convert the type to int\n",
    "    activation_map = np.uint8(255 * activation_map)\n",
    "\n",
    "\n",
    "    #convert to heatmap\n",
    "    heatmap = cv2.applyColorMap(activation_map, cv2.COLORMAP_JET)\n",
    "\n",
    "    #superimpose heatmap onto image\n",
    "    original_img = np.uint8((original_img - original_img.min()) / (original_img.max() - original_img.min()) * 255)\n",
    "    cvt_heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n",
    "    cvt_heatmap = img_to_array(cvt_heatmap)\n",
    "\n",
    "    #enlarge plot\n",
    "    plt.rcParams[\"figure.dpi\"] = 100\n",
    "\n",
    "    if plot_results == True:\n",
    "        plt.imshow(np.uint8(original_img * interpolant + cvt_heatmap * (1 - interpolant)))\n",
    "    else:\n",
    "        return cvt_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 6s 6s/step\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15800\\3481709865.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#apply function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mVizGradCAM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot_results\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15800\\1938183293.py\u001b[0m in \u001b[0;36mVizGradCAM\u001b[1;34m(model, image, interpolant, plot_results)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;31m#STEP 2: Create new model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;31m#specify last convolutional layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0mlast_conv_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[0mtarget_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlast_conv_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#load image\n",
    "img_path = \"C:/Users/Nina/Documents/GitHub/AVR23---BDS---Radio-Pulm/data/COVID/images/COVID-1.png\"\n",
    "img = image.load_img(img_path, target_size=(256,256))\n",
    "\n",
    "#apply function\n",
    "VizGradCAM(model, tf.keras.utils.img_to_array(img), plot_results=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
